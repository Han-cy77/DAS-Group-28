---
title: "Group_28_Analysis.qmd"
format: html
editor: visual
---

# 1. Background and Aims of the Analysis

With the growing importance of data-informed policymaking, identifying the socioeconomic factors that influence individual income has become a critical area of research. Leveraging the 1994 U.S. Census data, this study seeks to explore how personal and demographic characteristics correlate with income levels, particularly whether an individual earns more than \$50,000 per year.

The dataset includes various attributes such as age, education, marital status, occupation, sex, weekly working hours, and nationality. These features are believed to have different levels of influence on income. To investigate this, the study employs a Generalised Linear Model (GLM) with a logistic link function (logistic regression). In addition to this traditional statistical approach, we also apply machine learning models (e.g., decision trees or random forests) to the same data, allowing us to compare their predictive performance and interpretability against the GLM results.

The research objectives are threefold:

1.  **Feature Identification:** Determine which features derived from census data significantly impact an individual's income level, regardless of specific income thresholds.

2.  **Income Classification:** Identify the key factors that influence whether an individual earns more than \$50,000 per yearâ€”framing the problem as a binary classification task.

3.  **Practical Implications:** Interpret the model results in real-world terms, providing insight into how demographic or behavioral factors (like education level or working hours) may increase the likelihood of higher earnings, and how such findings could inform social and economic policy.

This study also addresses key challenges such as class imbalance, multicollinearity, and categorical data encoding, ensuring the reliability and relevance of the final model outputs. By combining classical statistical modeling with modern machine learning techniques, we aim to produce a robust, interpretable, and practically useful analysis of income determinants.

# 2. Exploratory Data Analysis

## 1. Import data and modify the columns

```{r}
#| message: false
#| echo: true

library(dplyr)
# import dataset and handle missing values
original_data <- read.csv('dataset28.csv', na.strings = '?,')
sum(is.na(original_data))
original_data <- na.omit(original_data)
dim(original_data)

# modify the Education column
# use 'Higher' to represent higher education level
# use 'Lower' to represent lower education level
unique(original_data$Education)
modified_data <- original_data
modified_data <- modified_data %>%
  mutate(
    Education_level = case_when(
      Education %in% c("Bachelors,", "Masters,", "Doctorate,", "Prof-school,") ~ "Higher",
      Education %in% c("Assoc-acdm,", "Assoc-voc,", "Some-college,", "HS-grad,") ~ "Medium",
      TRUE ~ "Lower"
    )
  )

# modify the Marital_Status column
# use 'Yes' or 'No' to represent whether a person has or not has partner
unique(original_data$Marital_Status)
modified_data$Has_partner <- ifelse(original_data$Marital_Status %in% c("Married-civ-spouse,", "Married-AF-spouse,"), "Yes", "No")

# modify the Nationality column
unique(original_data$Nationality)
modified_data$Nationality <- ifelse(original_data$Nationality %in% c('United-States,'), 'US_mainland', 'Others')

# modify the Occupantion column
unique(original_data$Occupation)
modified_data <- modified_data %>%
  mutate(
    Occupation = case_when(
      Occupation %in% c("Exec-managerial,", "Prof-specialty,", "Tech-support,") ~ "High-skilled jobs",
      Occupation %in% c("Adm-clerical,", "Sales,") ~ "Office & Sales jobs",
      Occupation %in% c("Craft-repair,", "Machine-op-inspct,", "Transport-moving,") ~ "Blue-collar jobs",
      TRUE ~ "Service & Labor jobs"
    )
  )

# delete useless columns
modified_data <- modified_data %>%
  dplyr::select(-c(Education, Marital_Status))



# modify other columns
columns_to_clean <- c('Sex', 'Hours_PW')
modified_data[columns_to_clean] <- lapply(modified_data[columns_to_clean], function(x) gsub(",$", "", x))

# check the modified data
dim(modified_data)
summary(modified_data)
str(modified_data)
modified_data$Hours_PW <- as.integer(modified_data$Hours_PW)
modified_data$Age <- as.integer(modified_data$Age)
modified_data$Occupation <- as.factor(modified_data$Occupation)
modified_data$Sex <- as.factor(modified_data$Sex)
modified_data$Nationality <- as.factor(modified_data$Nationality)
modified_data$Income <- as.factor(modified_data$Income)
modified_data$Education_level <- as.factor(modified_data$Education_level)
modified_data$Has_partner <- as.factor(modified_data$Has_partner)
str(modified_data)
```

The dataset, derived from the 1994 U.S. Census, was imported with missing values represented by `"?"`. After removing rows with any missing values (`na.omit()`), the final cleaned dataset contains **30,162 observations** and **8 core variables** relevant to individual socioeconomic characteristics and income level.

**Variable Transformation**

To improve interpretability and reduce dimensionality, several categorical variables were recoded as follows:

-   **Education**: Recoded into a new variable `Education_level` with three ordered categories:

\- \*Lower\* (e.g., primary school)

-   \*Medium\* (e.g., high school, some college)

-   \*Higher\* (e.g., Bachelors, Masters, Doctorate)

-   **Marital_Status**: Simplified to a binary variable `Has_partner`, indicating whether the individual has a spouse or not.

-   **Nationality**: Consolidated into two categories:

\- \`US_mainland\` for individuals born in the United States

-   \`Others\` for all other nationalities

-   **Occupation**: Grouped into four broader categories:

\- \*High-skilled jobs\* (e.g., professionals, tech support, managers)

-   \*Office & Sales jobs\*

-   \*Blue-collar jobs\* (manual labor, machine operation)

-   \*Service & Labor jobs\* (e.g., farming, cleaning, protective services)

Additionally, all character-based variables had trailing commas removed to ensure consistency, and data types were properly cast: numeric variables (`Age`, `Hours_PW`) and categorical variables (`Sex`, `Income`, etc.).

**Descriptive Statistics**

Below is a high-level summary of the main variables after transformation:

-   **Age**: Integer variable, with a wide range from young adults to elderly individuals. Summary statistics will help assess age-related income patterns.

-   **Hours_PW (Hours per Week)**: Integer variable capturing labor intensity. The average weekly working hours is expected to differ significantly between income groups.

-   **Sex**: Categorical (Male/Female). Used to examine gender-based income disparities.

-   **Income**: Binary factor (`<=50K`, `>50K`), our dependent variable for classification modeling.

-   **Education_level**: Factor with ordered levels. Anticipated to show strong correlation with income.

-   **Occupation**: Reclassified into four interpretable job categories, expected to influence earning potential.

-   **Nationality**: Categorical variable used to capture geographic origin and its socioeconomic implications.

-   **Has_partner**: Binary variable which may reflect family structure and economic stability.

**Initial Observations**

-   The dataset is relatively balanced in size and has undergone comprehensive cleaning to remove missing values.

-   Clear categorical consolidation has been applied to reduce dimensionality without sacrificing meaning.

-   The data is now well-structured and ready for GLM modeling and comparison with machine learning methods.

This preprocessing stage sets a solid foundation for robust model estimation and interpretation of income determinants. The modified variables are designed to improve both interpretability and statistical efficiency in subsequent modeling steps.

## 2. Check for Multi-Collinearity issues

```{r}
#| message: false
library(car)
# convert all variables including categorical variables into numeric variables
modified_data_numeric <- modified_data %>%
  # convert Education_level as 1, 2, 3
  mutate(
    Education_level = as.numeric(factor(Education_level, levels = c("Lower", "Medium", "Higher")))
  ) %>%
  # other categorical variables converted to 0 and 1
  mutate(
    Sex = ifelse(Sex == levels(Sex)[1], 0, 1),
    Nationality = ifelse(Nationality == levels(Nationality)[1], 0, 1),
    Income = ifelse(Income == levels(Income)[1], 0, 1),
    Has_partner = ifelse(Has_partner == levels(Has_partner)[1], 0, 1)
  ) %>%
  # others converted to numerical
  mutate_if(is.factor, as.numeric)

VIF_model <- lm(Income ~ ., data = modified_data_numeric)

# calculate VIF
vif_values <- vif(VIF_model)
print(vif_values)

high_vif <- vif_values[vif_values > 10]
if (length(high_vif) > 0) {
  print("Variables with multicollinearity problem:")
  print(high_vif)
} else {
  print("There is no serious multicollinearity problem.")
}
```

## 3. Check sample balance

```{r}
#| message: false
# calculate the sample sizes and proportions of different response
table(modified_data$Income)
prop.table(table(modified_data$Income))
```

## 4. Data visualization

Use chart and plots to summarize the data set.

```{r}
#| message: false
#| label: fig-score1
#| fig-cap: "Relationships Between Income and Ocupation"
#| fig-pos: "H"

library(ggplot2)

# Contingency Tables and Barplots for Categorical variables
# Occupation
Occupation_Income_table <- table(modified_data$Occupation, modified_data$Income)
print(Occupation_Income_table)

ggplot(data = modified_data, mapping = aes(x = Occupation, fill = Income)) +
  geom_bar(position = 'dodge') +
  scale_fill_manual(values = c("<=50K" = "#003B5C", ">50K" =
                                 "#ff7f0e")) +
  labs(title = 'Occupation vs Income', x = "Occupation",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

**Occupation vs. Income**

The Figure1 illustrates the relationship between occupation and income distribution:

-   **Blue-collar jobs**: 279 individuals earn **â‰¤50K**, while only 75 earn **\>50K**. This suggests that most blue-collar workers remain in the lower-income bracket.

-   **High-skilled jobs**: 225 individuals earn **â‰¤50K**, while a **significant 187 individuals** earn **\>50K**. This group has the **highest proportion** of high earners.

-   **Office & Sales jobs**: 284 individuals earn **â‰¤50K**, whereas only 54 individuals earn **\>50K**. This suggests that most individuals in this category remain in lower-income brackets.

-   **Service & Labor jobs**: 242 individuals earn **â‰¤50K**, while only 23 exceed the **50K** threshold, indicating **very limited upward income mobility**.

High-skilled jobs show the best income potential, while blue-collar and service jobs predominantly fall within the lower-income group.

```{r}
#| message: false
#| label: fig-score2
#| fig-cap: "Relationships Between Income and Sex"
#| fig-pos: "H"

# Sex
Sex_Income_table <- table(modified_data$Sex, modified_data$Income)
print(Sex_Income_table)

ggplot(data = modified_data, mapping = aes(x = Sex, fill = Income)) +
  geom_bar(position = 'dodge') +
  scale_fill_manual(values = c("<=50K" = "#003B5C", ">50K" =
                                 "#ff7f0e")) +
  labs(title = 'Sex vs Income', x = "Sex",
       y = "Count") +
  theme_minimal()
```

**Sex vs. Income**

The Figure2 provides insight into gender-based income disparities:

-   **Females**: 383 earn **â‰¤50K**, while only **51 earn \>50K**. This means only **11.8%** of females in the dataset belong to the high-income group.

-   **Males**: 647 earn **â‰¤50K**, while **288 earn \>50K**. In contrast to females, **30.8%** of males surpass the **50K** income level.

Males are nearly three times more likely to earn \>50K than females (30.8% vs. 11.8%), indicating a substantial gender wage gap. This could be due to occupational segregation, work experience, or systemic wage inequality.

```{r}
#| message: false
#| label: fig-score3
#| fig-cap: "Relationships Between Income and Nationality"
#| fig-pos: "H"

# Nationality
Nationality_Income_table <- table(modified_data$Nationality, modified_data$Income)
print(Nationality_Income_table)

ggplot(data = modified_data, mapping = aes(x = Nationality, fill = Income)) +
  geom_bar(position = 'dodge') +
  scale_fill_manual(values = c("<=50K" = "#003B5C", ">50K" =
                                 "#ff7f0e")) +
  labs(title = 'Nationality vs Income', x = "Nationality",
       y = "Count") +
  theme_minimal()
```

**Nationality vs. Income**

The Figure3 explores how income distribution varies by nationality:

-   **US Mainland-born individuals**: 924 earn **â‰¤50K**, while **316 earn \>50K**. This means **25.5%** of this group reaches high-income status.

-   **Others (foreign-born individuals)**: 106 earn **â‰¤50K**, whereas only **23 individuals** earn **\>50K**, meaning only **17.8%** enter the high-income bracket.

Individuals born in the US Mainland are more likely to earn \>50K (25.5%) compared to those born elsewhere (17.8%). This suggests that US-born individuals may have an advantage in accessing higher-paying jobs, possibly due to factors such as language proficiency, education access, or reduced work restrictions.

```{r}
#| message: false
#| label: fig-score4
#| fig-cap: "Relationships Between Income and Education level"
#| fig-pos: "H"

# Education level
Education_Income_table <- table(modified_data$Education_level, modified_data$Income)
print(Education_Income_table)

ggplot(data = modified_data, mapping = aes(x = Education_level, fill = Income)) +
  geom_bar(position = 'dodge') +
  scale_fill_manual(values = c("<=50K" = "#003B5C", ">50K" =
                                 "#ff7f0e")) +
  labs(title = 'Education level vs Income', x = "Education level",
       y = "Count") +
  theme_minimal()
```

**Education Level vs. Income**

The Figure4 examines the impact of education on income:

-   **Higher Education (Bachelorâ€™s, Masterâ€™s, Doctorate, etc.)**: **165 earn â‰¤50K**, while **173 earn \>50K**. Notably, this is **the only group where more individuals earn \>50K than â‰¤50K**.

-   **Medium Education (High school graduates, associate degrees, some college)**: **715 earn â‰¤50K**, whereas only **153 earn \>50K**, meaning only **17.6% of this group achieves high income**.

-   **Lower Education (Elementary/Middle school and below)**: **150 earn â‰¤50K**, and only **13 earn \>50K**, meaning an extremely low **8.0%** of this group surpasses the **50K** income level.

Higher education significantly increases the probability of earning \>50K. Nearly 51.2% of highly educated individuals enter the high-income bracket, compared to 17.6% for medium education and just 8.0% for lower education. This highlights education as a major determinant of economic mobility.

```{r}
#| message: false
#| label: fig-score5
#| fig-cap: "Relationships Between Income and Partner"
#| fig-pos: "H"

# Partner
Partner_Income_table <- table(modified_data$Has_partner, modified_data$Income)
print(Partner_Income_table)

ggplot(data = modified_data, mapping = aes(x = Has_partner, fill = Income)) +
  geom_bar(position = 'dodge') +
  scale_fill_manual(values = c("<=50K" = "#003B5C", ">50K" =
                                 "#ff7f0e")) +
  labs(title = 'Partner vs Income', x = "Partner",
       y = "Count") +
  theme_minimal()
```

**Marital Status vs. Income (Partner vs. Income)**

The Figure5 investigates the impact of marital status on income:

-   **Individuals without a partner**: **675 earn â‰¤50K**, while only **44 earn \>50K**. This means only **6.1%** of single individuals surpass the **50K** threshold.

-   **Individuals with a partner**: **355 earn â‰¤50K**, while **295 earn \>50K**, meaning **45.4%** earn \>50K.

Key Insight: Individuals with a partner are significantly more likely to earn \>50K (45.4%) than those without a partner (6.1%). This might be due to dual-income households, financial stability, or career advancement associated with family life.

```{r}
#| message: false
#| label: fig-score6
#| fig-cap: "Relationships Between Income and Age"
#| fig-pos: "H"

# Violin plots and boxplots for numerical continuous variables
# Age
ggplot(data = modified_data, aes(x = Income, y = Age, fill = Income)) +
  geom_violin(col = 'transparent') +
  scale_fill_manual(values = c("<=50K" = "#7f7f7f", ">50K" =
                                 "#ffdd57")) +
  labs(title = "Age vs Income", x = "Income", y = "Age") +
  theme_minimal()

ggplot(modified_data, aes(x = Income, y = Age, fill = Income)) +
  geom_boxplot() +
  labs(title = "Age vs Income", x = "Income", y = "Age") +
  theme_minimal()

```

**1. Age vs. Income Analysis (Violin Plot)**

The violin plot visualizes the **distribution of age across income levels (â‰¤50K vs. \>50K)**:

-   The **â‰¤50K income group (gray)** has a **broader and more left-skewed distribution**, with a **higher density of individuals between 25 and 35 years old**. This suggests that **younger individuals are more likely to earn lower incomes**, potentially due to **limited work experience and early career positioning**.

-   The **\>50K income group (yellow)** is more concentrated, with most individuals **falling between 35 and 55 years old**, indicating that **higher earnings are more common among middle-aged individuals**.

-   The **older population (60+) appears less frequent in both groups**, likely due to **retirement or workforce transition**.

Key Insight: Individuals aged 35-55 are more likely to earn \>50K, aligning with income growth over time as experience accumulates. Younger individuals tend to stay in the â‰¤50K group, supporting the idea that career progression plays a critical role in achieving higher income levels.

**2. Age vs. Income Analysis (Boxplot)**

The boxplot further breaks down the **age distribution by income level**, offering a more structured comparison:

-   **â‰¤50K Income Group (Red Boxplot)**:

```         
-   **Median age**: Approximately **35 years old**.

-   **Interquartile range (IQR)**: Most individuals fall between **25 and 45 years old**.

-   **Outliers above 70 years old** suggest that some older individuals continue working but remain in lower-income brackets.
```

-   **\>50K Income Group (Blue Boxplot)**:

```         
-   **Median age**: Closer to **45 years old**, significantly higher than the â‰¤50K group.

-   **IQR range**: Most individuals are between **35 and 55 years old**.

-   **Fewer younger individuals (\<30) are present in this group**, reinforcing the correlation between **work experience and income growth**.
```

Key Insight: The median age in the \>50K group is notably higher than in the â‰¤50K group. This suggests that experience and career longevity contribute significantly to income levels, and younger individuals are far less likely to reach the \>50K threshold.

**Conclusion**

Both visualizations confirm that **age is a significant factor in income level**:

1.  **Younger individuals (25-35) are concentrated in the â‰¤50K group**, likely due to **early career stages and lower seniority**.

2.  **Middle-aged individuals (35-55) dominate the \>50K group**, reinforcing **the positive impact of experience and career advancement on earnings**.

3.  **The median age of high-income earners is \~45, while low-income earners have a median age of \~35**, highlighting the **age-income relationship**.

These insights will be valuable in our **Generalized Linear Model (GLM) and machine learning approaches**, as **age is expected to be a strong predictor of income classification**.

```{r}
#| message: false
#| label: fig-score7
#| fig-cap: "Relationships Between Income and Hours Per Week"
#| fig-pos: "H"

# Hours per week
ggplot(data = modified_data, aes(x = Income, y = Hours_PW, fill = Income)) +
  geom_violin(col = 'transparent') +
  scale_fill_manual(values = c("<=50K" = "#7f7f7f", ">50K" =
                                 "#ffdd57")) +
  labs(title = "Hours Per Week vs Income", x = "Income", y = "Hours_PW") +
  theme_minimal()

ggplot(modified_data, aes(x = Income, y = Hours_PW, fill = Income)) +
  geom_boxplot() +
  labs(title = "Hours Per Week vs Income", x = "Income", y = "Hours per Week") +
  theme_minimal()
```

**1. Hours Worked Per Week vs. Income (Violin Plot Analysis)**

The violin plot visualizes the distribution of **weekly working hours (Hours_PW) across income levels (â‰¤50K vs. \>50K)**:

-   **â‰¤50K Income Group (gray)**:

```         
-   The distribution is **more spread out**, with a **high density of individuals working around 40 hours per week**.

-   A significant portion of individuals works **less than 40 hours per week**, suggesting that part-time or lower-hour jobs may be contributing factors to lower income.

-   The presence of **some outliers working more than 75 hours per week but still earning â‰¤50K** may indicate jobs with overtime but lower hourly wages.
```

-   **\>50K Income Group (yellow)**:

```         
-   The distribution is **more concentrated around 45-50 hours per week**, showing that **higher-income individuals tend to work longer hours**.

-   The tail of the distribution extends to **over 80-100 hours per week**, indicating that **some high earners work extreme hours, possibly in high-responsibility roles or self-employment**.
```

Key Insight: Higher-income individuals (\>50K) generally work more hours per week, while those working fewer than 40 hours per week rarely earn \>50K. This suggests that longer work commitments and job type significantly impact income levels.

**2. Hours Worked Per Week vs. Income (Boxplot Analysis)**

The boxplot provides a more structured comparison of **weekly working hours** between the two income groups:

-   **â‰¤50K Income Group (Red Boxplot)**:

```         
-   **Median working hours**: **40 hours per week**, with most individuals working between **35 and 45 hours**.

-   **Interquartile range (IQR)**: The majority of individuals fall between **25 and 45 hours per week**.

-   **Numerous outliers working beyond 60-70 hours per week but still earning â‰¤50K**, indicating that longer hours do not always correlate with higher income in lower-paying jobs.
```

-   **\>50K Income Group (Blue Boxplot)**:

```         
-   **Median working hours**: **closer to 50 hours per week**, higher than the â‰¤50K group.

-   **IQR Range**: Most individuals work **between 40 and 55 hours per week**, showing a shift toward longer work hours.

-   **Outliers extending to 80-100 hours per week**, reinforcing the observation that **some high earners work significantly more hours** than the general population.
```

Key Insight: The median working hours for \>50K earners is higher (around 50 hours per week) than for â‰¤50K earners (40 hours per week). This supports the conclusion that higher income is correlated with longer work hours, but extreme hours do not guarantee high earnings. The presence of long-hour workers in the â‰¤50K group suggests wage structure and job type are additional influencing factors.

**Conclusion**

1.  **Higher-income individuals (\>50K) tend to work longer hours**, with the median workweek being **\~50 hours**, whereas **lower-income individuals (â‰¤50K) have a median of \~40 hours**.

2.  **Most individuals working fewer than 40 hours per week remain in the â‰¤50K category**, suggesting that **part-time work or shorter-hour jobs are associated with lower earnings**.

3.  **A small group of individuals working extreme hours (\>80 per week) exists in both income groups**, highlighting **variability in income generation based on industry and job type**.

These insights reinforce the importance of work hours as a key variable in predicting income and will be valuable for Generalized Linear Model (GLM) and machine learning modeling in further analysis.

# 3. Data Splitting: Training set and Test set

```{r}
#| message: false
library(caret)
# set random seed
set.seed(123)

# create training index for stratified sampling
training_index <- createDataPartition(modified_data$Income, p = 0.8, list = FALSE)

# split data into training data and test data
training_data <- modified_data[training_index, ]
test_data  <- modified_data[-training_index, ]
str(training_data)
str(test_data)

# Replace Spaces and ampersand with underscores _
training_data$Occupation <- gsub(" & ", "_", training_data$Occupation)  
training_data$Occupation <- gsub(" ", "_", training_data$Occupation)    

test_data$Occupation <- gsub(" & ", "_", test_data$Occupation)  
test_data$Occupation <- gsub(" ", "_", test_data$Occupation)

# Make sure the variable is still a factor type
training_data$Occupation <- as.factor(training_data$Occupation)

test_data$Occupation <- as.factor(test_data$Occupation)

# View the modified categories
levels(training_data$Occupation)

levels(test_data$Occupation)




# check dimension
dim(training_data)
dim(test_data)

# check distribution in both datasets
prop.table(table(training_data$Income))
prop.table(table(test_data$Income))
```

# 4. Statistical Modelling and Results

## 1. Statistical Modelling

### 1. GLM

#### 1.Model Fitting

```{r}
#| message: false
library(MASS)
library(caret)
library(pROC)
library(pscl)

# Create dummy variables
dummy_variables <- model.matrix(~ Occupation - 1, data = training_data)
education_dummy <- model.matrix(~ Education_level - 1, data = training_data)
nationality_dummy <- model.matrix(~ Nationality - 1, data = training_data)
has_partner_dummy <- model.matrix(~ Has_partner - 1, data = training_data)
sex_dummy <- model.matrix(~ Sex - 1, data = training_data)
has_partner_dummy <- model.matrix(~ Has_partner - 1, data = training_data)

#Handle non-standard characters
col_names <- c("OccupationBlue-collar jobs",    
               "OccupationHigh-skilled jobs",  
               "OccupationOffice & Sales jobs",  
               "OccupationService & Labor jobs")
clean_col_names <- gsub("[^a-zA-Z0-9]", "_", col_names)   
clean_col_names <- gsub("_+", "_", clean_col_names) 
clean_col_names <- gsub("_$", "", clean_col_names) 
print(clean_col_names)
# Define training_data_GLM
training_data_GLM <- training_data
colnames(training_data_GLM)[which(colnames(training_data_GLM) %in% col_names)] <- clean_col_names


#Check new variables
colnames(dummy_variables)
colnames(education_dummy)
colnames(nationality_dummy)
colnames(has_partner_dummy)
colnames(sex_dummy)


# Add the dummy variables into the original dataset
training_data_GLM <- cbind(training_data_GLM, dummy_variables)
training_data_GLM  <- cbind(training_data_GLM, education_dummy)
training_data_GLM  <- cbind(training_data_GLM, nationality_dummy)
training_data_GLM  <- cbind(training_data_GLM, has_partner_dummy)
training_data_GLM  <- cbind(training_data_GLM, sex_dummy)

full_model <- glm(Income ~ (Age + Occupation + Sex + Hours_PW + Nationality + Education_level + Has_partner)^2, 
                  data = training_data_GLM , family = binomial)


step_model <- stepAIC(full_model, direction = "both", trace = FALSE)
summary(step_model)


test_data$predicted_prob <- predict(step_model, newdata = test_data, type = "response")
test_data$predicted_class <- ifelse(test_data$predicted_prob >= 0.5, ">50K", "<=50K")
test_data$predicted_class <- factor(test_data$predicted_class, levels = levels(test_data$Income))


conf_matrix <- confusionMatrix(test_data$predicted_class, test_data$Income)
print(conf_matrix)


roc_curve <- roc(test_data$Income, test_data$predicted_prob)
auc_score <- auc(roc_curve)
print(auc_score)
plot(roc_curve, col = "blue", main = "ROC Curve for Logistic Regression")


pseudo_r2 <- pR2(step_model)
print(pseudo_r2)

```

#### 2. Model Optimization

```{r}
# Load necessary libraries
library(MASS)  # stepAIC()
library(car)   # VIF
library(pROC)  # AUC calculation
library(dplyr) # Data manipulation

# Step 1: Select the best main effects model
base_model <- glm(Income ~ Age + Occupation + Sex + Hours_PW + Nationality + Education_level + Has_partner, 
                  data = training_data_GLM , family = binomial)

step_base_model <- stepAIC(base_model, direction = "both", trace = FALSE)

summary(step_base_model)  # View the optimized main effects model

# Step 2: Check interaction effects
interaction_model <- glm(Income ~ Age + Occupation + Hours_PW + Nationality + 
                           Education_level + Has_partner +
                           Education_level:Occupation + Hours_PW:Occupation,
                         data = training_data_GLM , family = binomial)

anova(step_base_model, interaction_model, test = "Chisq")  # Perform likelihood ratio test

# Step 3: Use stepAIC() to select the final model
final_model <- stepAIC(interaction_model, direction = "both", trace = FALSE)

summary(final_model)  # View the final model

# Step 4: Generate dummy variables (Ensure that OccupationService_Labor_jobs exists)
training_data$Occupation <- as.factor(training_data$Occupation)
occupation_dummy <- model.matrix(~ Occupation - 1, data = training_data_GLM ) %>% as.data.frame()
training_data <- cbind(training_data_GLM , occupation_dummy)

# Check if `OccupationService_Labor_jobs` is included
colnames(training_data)

View(training_data_GLM)




# Step 5: Refit the final optimized model
final_model_refined <- glm(Income ~ Age + OccupationService_Labor_jobs + Hours_PW + 
                             Nationality + Education_level + Has_partner + 
                             OccupationService_Labor_jobs:Hours_PW, 
                           family = binomial, data = training_data_GLM)

summary(final_model_refined)  # Check statistical significance

# Step 6: Check VIF (Multicollinearity)
vif(final_model_refined)

# Standardize variables
training_data_GLM $Hours_PW <- scale(training_data_GLM $Hours_PW)
training_data_GLM $OccupationService_Labor_jobs <- scale(training_data_GLM $OccupationService_Labor_jobs)

# Refit the model
final_model_refined <- glm(Income ~ Age + OccupationService_Labor_jobs + Hours_PW + 
                             Nationality + Education_level + Has_partner + 
                             OccupationService_Labor_jobs:Hours_PW, 
                           family = binomial, data = training_data_GLM )

# Recheck VIF
vif(final_model_refined)

# Step 7: Compute AUC to evaluate classification performance
roc_curve <- roc(training_data_GLM $Income, fitted(final_model_refined))
auc(roc_curve)  # Compute AUC value
plot(roc_curve) # Plot ROC curve

```

During the model optimization process, we applied main effect selection, ANOVA interaction testing, and stepwise AIC optimization to construct a robust model, retaining statistically significant variables (p \< 0.05) while removing non-significant ones (p \> 0.1). The final model achieved a residual deviance of 773.01 and an AIC of 793.01, with six Fisher Scoring iterations, indicating stability. ANOVA testing confirmed significant interaction effects (p \< 0.05), leading to further refinement using stepAIC(), and the model demonstrated strong predictive performance with an AUC of 0.8871. Initially, multicollinearity was detected (VIF \> 10) for OccupationService_Labor_jobs and its interaction with Hours_PW, but after standardizing relevant variables, all VIF values fell below 2, effectively resolving the issue.

#### 3. Analysis and Results

After model optimization, the residual deviance decreased substantially from 1228.22 to 779.05, and the final model achieved an AIC of 797.05, indicating an improved model fit with an optimal balance between complexity and performance; additionally, the ROC-AUC of 0.8871 reflects strong classification ability, the inclusion of interaction terms significantly enhanced model fit (p = 0.0019), and all GVIF values were below 2, confirming the absence of multicollinearity and overall model stability.

It can be indicated that GLM model highlighted the following most significant factors :

-   **Age**: Positively associated with income, indicating that older individuals tend to earn more.

-   **Hours Worked Per Week (Hours_PW)**: A strong positive effect, suggesting that individuals working longer hours are more likely to earn over \$50,000.

-   **Education Level**: Lower and medium education levels are significantly negatively associated with high income compared to the reference (higher education), underlining the importance of education in income stratification.

-   **Has Partner** : A strong positive effect, implying that individuals with a partner are more likely to earn more.

-   **Nationality** : Being a US mainland resident significantly increases the likelihood of higher income.

-   **Occupation** : This category has a significant negative interaction with working hours, meaning that in labor-intensive jobs, working longer hours doesn't increase income as much as in other occupations.

For practical implications, our findings offer valuable insights for **economic and social policy-making**:

-   **Educational Attainment**: Investment in higher education yields significant returns in income, suggesting policymakers should prioritize educational access and quality.

-   **Work Intensity**: Working longer hours correlates with higher income, especially in non-labor-intensive jobs, which could inform labor regulations and occupational health policies.

-   **Marital Status**: The strong influence of having a partner implies social and economic stability may contribute to income potential.

-   **Nationality and Residency**: Disparities between mainland and non-mainland residents may highlight structural differences in labor markets.

### 2. Random Forest

#### 1. Model Fitting

```{r}
library(randomForest)  
library(caret)        
library(pROC)         
library(rpart.plot)

training_data <- modified_data[training_index, ]
test_data  <- modified_data[-training_index, ]

training_data$Income <- as.factor(training_data$Income)
test_data$Income <- as.factor(test_data$Income)

# Ensure that the target variable is a factor type
training_data$Income <- as.factor(training_data$Income)
test_data$Income <- as.factor(test_data$Income)


# Constructing random forest model
set.seed(123)  
rf_model <- randomForest(
  Income ~ .,                
  data = training_data,      
  ntree = 500,               
  mtry = sqrt(ncol(training_data) - 1), importance = TRUE, proximity = TRUE)  

# View model summary
print(rf_model)
plot(rf_model) 
# Extract the first tree in a random forest
tree <- getTree(rf_model, k = 1, labelVar = TRUE)
print(tree)

# Extract OOB errors
oob_errors <- rf_model$err.rate

# Convert OOB errors to a data frame for plotting
oob_df <- data.frame(
  Trees = 1:nrow(oob_errors),
  OOB_Error = oob_errors[, "OOB"])

# Plot the OOB error curve
ggplot(oob_df, aes(x = Trees, y = OOB_Error)) +
  geom_line(color = "blue", size = 1) +
  labs(
    title = "OOB Error Curve for Random Forest",
    x = "Number of Trees",
    y = "OOB Error") 



# Variable importance analysis
importance(rf_model)
varImpPlot(rf_model, main = "Variable Importance Plot")

#Define test_data_rf
test_data_rf <- test_data
# Prediction on test set
test_data_rf$predicted_prob <- predict(rf_model, newdata = test_data, type = "prob")[, 2]
test_data_rf$predicted_class <- predict(rf_model, newdata = test_data, type = "response")

# Calculate confusion matrix
conf_matrix <- confusionMatrix(test_data_rf$predicted_class, test_data_rf$Income)
print(conf_matrix)

# Calculate ROC-AUC
roc_curve <- roc(test_data_rf$Income, test_data_rf$predicted_prob)
auc_score <- auc(roc_curve)
print(auc_score)
plot(roc_curve, col = "blue", main = "ROC Curve for Random Forest Model")


```

#### 2.Analysis and Results

The OOB error rate is 17.06%, which means the model misclassifies approximately 17.06% of the training data on average. This is a good estimate of the model's generalization error. The model achieves good accuracy (80.59%) and a high AUC score (0.8632), indicating strong overall performance. However, the lower specificity for the \>50K class highlights the need to address class imbalance and refine the model further.

It can be indicated that random forest model highlighted the following most significant factors :

-   **Has Partner**: The most influential variable in both MeanDecreaseAccuracy and MeanDecreaseGini scores, suggesting a strong correlation between marital status and income.

-   **Education Level**: Higher education was strongly associated with income above \$50,000.

-   **Age**: A higher age generally corresponded with a higher likelihood of earning more.

-   **Occupation**: Professional and specialized jobs showed a strong correlation with higher income.

-   **Weekly Working Hours (Hours_PW)**: More working hours were linked to increased income.

Additionally, **Sex and Nationality** had lower importance scores, suggesting that while they contribute to income predictions, their impact is relatively minor compared to factors like education and occupation.

For practical implications, our findings offer valuable insights for **economic and social policy-making**:

-   **Education and Training Programs**: Policies aimed at increasing access to higher education and vocational training can improve income potential.

-   **Workforce and Labor Laws**: The correlation between income and weekly work hours suggests that employment policies, such as wage regulations and overtime laws, play a role in earnings.

-   **Family and Social Benefits**: The strong impact of marital status on income implies that family-related policies (e.g., tax benefits for married couples) may influence economic stability.

### 3. Model Comparison

Comparative Summary of Models

::: center
| Metric | Random Forest Model | GLM Model |
|----|----|----|
| **AUC** | 0.8632 | 0.8871 |
| **Interpretability** | Low (Black Box) | Strong |
| **Interaction Modeling** | Implicitly Included | Explicitly Modeled |
| **Model Suitability** | Suitable for High-Dimensional, Nonlinear Data | Suitable for Interpretation and Inference |
| **Class Balance Sensitivity** | Relatively High | Adjustable via Weighting |
:::

While both GLM and Random Forest demonstrate strong predictive performance (AUC: 0.8871 vs. 0.8632), GLM proves to be the superior model in this study due to its interpretability, statistical inference, and suitability for policy-oriented research. Unlike the black-box nature of Random Forest, GLM provides explicit coefficients, enabling hypothesis testing and direct interpretation of how factors such as education, working hours, and marital statusinfluence income. Additionally, GLM effectively models interaction effects, revealing significant relationships, such as the limited income benefits of longer working hours in labor-intensive jobs. Multicollinearity was addressed through standardization (VIF \< 2), ensuring model stability.

From a policy perspective, GLM's transparency makes it ideal for guiding education and labor policies, while Random Forest, despite its predictive strength, lacks explanatory power. Thus, GLM is the more suitable model for understanding income determinants in this study.

## 2. Results

This study aimed to identify key socioeconomic factors influencing income, classify individuals based on their income levels, and provide insights for policy implications. The GLM modelÂ proved to be the superior approach in achieving these objectives, as it explicitly quantifies the relationships between predictors and income, allowing for statistical inference and hypothesis testing. It revealed that education level, weekly working hours, and marital status are significant determinants of income, with education playing the most critical role. The model also demonstrated that in labor-intensive occupations, working longer hours does not necessarily increase income, highlighting structural disparities in the labor market.

In contrast, while the Random Forest model provided strong predictive accuracy, it did not offer the same level of interpretability. It was able to capture complex, nonlinear relationships but lacked the ability to test the significance of variables or interactions directly. This limits its usefulness in understanding why certain factors impact income and in making evidence-based policy recommendations.

Overall, GLM is the more suitable model for this study, as it not only classifies income levels effectively but also provides meaningful insights into the underlying economic mechanisms. Its ability to model interactions and resolve multicollinearity issues ensures robust and reliable results, making it a valuable tool for informing education policies, labor regulations, and social welfare programs.
